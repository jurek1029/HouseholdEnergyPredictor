{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c79977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "from MyTransformers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#%config Completer.use_jedi = False\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e3e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_path = \"Data/London/daily_dataset/daily_dataset/\"\n",
    "daily_weather_path = 'Data/London/weather_daily_darksky.csv'\n",
    "holiday_data_path = 'Data/London/uk_bank_holidays.csv'\n",
    "house_info_data_path = 'Data/London/informations_households.csv'\n",
    "\n",
    "hhour_data_path = \"Data/London/halfhourly_dataset/halfhourly_dataset/\"\n",
    "hourly_weather_path = 'Data/London/weather_hourly_darksky.csv'\n",
    "\n",
    "\n",
    "f_energy_all_name = \"energy_all.csv\"\n",
    "f_energy_hh_all_name = \"energy_hh_all.csv\"\n",
    "\n",
    "f_data_path = \"PrepedData/\"\n",
    "f_test_path = f_data_path + \"Test/\"\n",
    "f_energy_clean_name = \"energy_clean\"\n",
    "\n",
    "f_energy_avg_name = f_data_path + \"energy_avg\"\n",
    "f_energy_avg_hhourly_name = \"energy_avg_hhourly\"\n",
    "\n",
    "f_holiday_data_sufix = \"_hdata\"\n",
    "\n",
    "#tmp_path = \"tmp/\"\n",
    "#if not os.path.exists(tmp_path):\n",
    "#    os.mkdir(tmp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da3a16",
   "metadata": {},
   "source": [
    "## Load blocked data and create 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c3803c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Daily Data from bolcks and save to file\n",
    "fout= open(f_data_path + f_energy_all_name,\"w\")\n",
    "\n",
    "dtypes = {'LCLid':'str', 'day':'str', 'energy_median':'float', 'energy_mean':'float', 'energy_max':'float',\n",
    "          'energy_count':'int', 'energy_std':'float', 'energy_sum':'float', 'energy_min':'float'}\n",
    "\n",
    "for num in range(0,112):\n",
    "    df = pd.read_csv(f\"{daily_data_path}block_{str(num)}.csv\", dtype=dtypes, parse_dates=['day'] )\n",
    "    df.rename(columns = {\"day\": \"date\"}, inplace = True)\n",
    "    df = df[['LCLid','date','energy_sum']]\n",
    "    df.to_csv(f_energy_all_name, mode='a', index=False, header=num==0) #Add header only once\n",
    "    progres_bar(num,112)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63ed5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>███████████████████████████████████████████████████████████████| 99.11%%\n",
      "RangeIndex: 167817021 entries, 0 to 167817020\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   LCLid           object        \n",
      " 1   tstp            datetime64[ns]\n",
      " 2   energy(kWh/hh)  float32       \n",
      "dtypes: datetime64[ns](1), float32(1), object(1)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "# Load HHour Data from bolcks to RAM\n",
    "#fout= open(f_data_path + f_energyh_all_name,\"w\")\n",
    "#dtypes = {'LCLid':'str', 'tstp':'str', 'energy(kWh/hh)':'float'}\n",
    "dfs = []\n",
    "for num in range(0,112):\n",
    "    df = pd.read_csv(f\"{hhour_data_path}block_{str(num)}.csv\", parse_dates=['tstp'] ,na_values=['Null'] )\n",
    "    # df = pd.read_csv(f\"{hhour_data_path}block_{str(num)}.csv\", parse_dates=['tstp'] ,engine='pyarrow',na_values=['Null'] )\n",
    "    df['energy(kWh/hh)'] =  pd.to_numeric(df['energy(kWh/hh)'], errors='coerce',downcast='float')\n",
    "    #df.rename(columns = {\"tstp\": \"date\"}, inplace = True)\n",
    "    dfs.append(df)\n",
    "    progres_bar(num,112)\n",
    "    \n",
    "energy_hhour = pd.concat(dfs, ignore_index=True)\n",
    "#energy_hhour['energy(kWh/hh)'] =  pd.to_numeric(energy_hhour['energy(kWh/hh)'], errors='coerce',downcast='float')\n",
    "energy_hhour.info()\n",
    "#fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "185f9984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 167817021 entries, 0 to 167817020\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   LCLid           object        \n",
      " 1   tstp            datetime64[ns]\n",
      " 2   energy(kWh/hh)  float32       \n",
      "dtypes: datetime64[ns](1), float32(1), object(1)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "energy_hhour.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426ea38",
   "metadata": {},
   "source": [
    "# Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd757cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_in = {'LCLid':'str', 'date': 'str','energy_sum':'float', 'day': 'int8', 'month': 'int8', 'year': 'int16'}\n",
    "energy = pd.read_csv(f_energy_all_name, dtype=dtypes_in)\n",
    "energy.date = pd.to_datetime(energy.date,format='%Y-%m-%d').dt.date\n",
    "#energy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095a699",
   "metadata": {},
   "source": [
    "#### Daily weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ec16c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(daily_weather_path)\n",
    "weather['date']=  pd.to_datetime(weather['time'], format='%Y-%m-%d').dt.date # day is given as timestamp\n",
    "weather = weather[['temperatureMax','date']]\n",
    "#weather = weather[['temperatureMax', 'windBearing', 'dewPoint', 'cloudCover', 'windSpeed',\n",
    "#       'pressure', 'apparentTemperatureHigh', 'visibility', 'humidity',\n",
    "#       'apparentTemperatureLow', 'apparentTemperatureMax', 'uvIndex',\n",
    "#       'temperatureLow', 'temperatureMin', 'temperatureHigh',\n",
    "#       'apparentTemperatureMin', 'moonPhase','date']]\n",
    "#imputer = SimpleImputer(strategy=\"median\")\n",
    "#imputer.fit(weather)\n",
    "#X = imputer.transform(weather)\n",
    "#weather = pd.DataFrame(X, columns=weather.columns, index=weather.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da11d9a",
   "metadata": {},
   "source": [
    "#### HHour Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d1dab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_weatherh = {'temperature':'float32'}\n",
    "weather_h = pd.read_csv(hourly_weather_path,dtype=dtypes_weatherh)\n",
    "weather_h['date']=  pd.to_datetime(weather_h['time'], format='%Y-%m-%d %H:%M')\n",
    "weather_h = weather_h[['temperature','date']]\n",
    "weather_h = weather_h.dropna()\n",
    "\n",
    "l = len(weather_h.index)\n",
    "for i in range(1,l):\n",
    "    t_avg = (weather_h.loc[i-1].temperature + weather_h.loc[i].temperature ) / 2\n",
    "    date = weather_h.loc[i-1].date\n",
    "    date = date.replace(minute=30)\n",
    "    weather_h.loc[len(weather_h.index)] = [t_avg, date]\n",
    "    \n",
    "weather_h = weather_h.sort_values(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "424bc61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_h.to_csv(f_data_path + 'weather_hhourly_darksky.csv', mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d68466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_h = pd.read_csv(f_data_path + 'weather_hhourly_darksky.csv',dtype={ 'temperature':'float32','date':'str'})\n",
    "weather_h['date']=  pd.to_datetime(weather_h['date'], format='%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a6396b",
   "metadata": {},
   "source": [
    "#### Holiday dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa319e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday = pd.read_csv(holiday_data_path)\n",
    "holiday['Bank holidays'] = pd.to_datetime(holiday['Bank holidays'],format='%Y-%m-%d').dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a1c30",
   "metadata": {},
   "source": [
    "#### Household infor Acorn index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ecc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_info = pd.read_csv(house_info_data_path)\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(house_info[['Acorn']])\n",
    "house_info['Acorn_category'] = housing_cat_encoded\n",
    "house_info = house_info[['LCLid', 'Acorn_category']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f7a5a",
   "metadata": {},
   "source": [
    "# Save daily Clean data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0301c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_info = energy.merge(weather,on='date')\n",
    "energy_info = energy_info.merge(holiday, left_on = 'date',right_on = 'Bank holidays',how = 'left')\n",
    "energy_info['holiday_ind'] = np.where(energy_info['Bank holidays'].isna(),0,1)\n",
    "energy_info = energy_info.merge(house_info, on = ['LCLid'])\n",
    "energy_info = energy_info[['LCLid', 'date','energy_sum', 'temperatureMax', 'holiday_ind', 'Acorn_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b2e5bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650.0 629.9475386273805\n",
      "              date   energy_sum  temperatureMax  holiday_ind  Acorn_category\n",
      "count  5566.000000  5566.000000     5566.000000  5566.000000     5566.000000\n",
      "mean    629.952928   629.947539      629.952928   629.952928      629.952928\n",
      "std     112.066799   112.088978      112.066799   112.066799      112.066799\n",
      "min       1.000000     0.000000        1.000000     1.000000        1.000000\n",
      "25%     599.000000   599.000000      599.000000   599.000000      599.000000\n",
      "50%     650.000000   650.000000      650.000000   650.000000      650.000000\n",
      "75%     683.000000   683.000000      683.000000   683.000000      683.000000\n",
      "max     829.000000   829.000000      829.000000   829.000000      829.000000\n"
     ]
    }
   ],
   "source": [
    "households = energy_info.groupby('LCLid').count()\n",
    "print(households['date'].median(), households['energy_sum'].mean())\n",
    "print(households.describe())\n",
    "\n",
    "h_names_small_data_size = households[households['energy_sum'] < 600].index\n",
    "s = set(h_names_small_data_size)\n",
    "b = [e not in s for e in energy_info['LCLid']]\n",
    "energy_clean = energy_info[b]\n",
    "energy_clean = energy_clean.reset_index()\n",
    "\n",
    "#weather_energy_clean =  energy_clean.merge(weather,on='date')\n",
    "#weather_energy_clean = weather_energy_clean[['LCLid','energy_sum', 'day', 'month','temperatureMax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a71cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_clean.to_csv(f_data_path + f_energy_clean_name+\"_all.csv\", mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65abc9",
   "metadata": {},
   "source": [
    "### Create test train splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f84f1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(energy_clean, energy_clean['Acorn_category']):\n",
    "    strat_train_set = energy_clean.loc[train_index]\n",
    "    strat_test_set = energy_clean.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "009ebc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.to_csv(f_data_path + f_energy_clean_name+\"_strat.csv\", mode='w', index=False, header=True) \n",
    "strat_test_set.to_csv(f_test_path + f_energy_clean_name+\"_strat.csv\", mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5420e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_clean_train_set, e_clean_test_set = train_test_split(energy_clean, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82482232",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_clean_train_set.to_csv(f_data_path + f_energy_clean_name+\".csv\", mode='w', index=False, header=True) \n",
    "e_clean_test_set.to_csv(f_test_path + f_energy_clean_name+\".csv\", mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b20f5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = round(house_info[\"Acorn_category\"].value_counts() * 0.1)\n",
    "#shuffle data if deemed necessery \n",
    "test_ids = []\n",
    "for idx , r in house_info.iterrows():\n",
    "    if test[r.Acorn_category] > 0 :\n",
    "        test_ids.append(r.LCLid)\n",
    "        test[r.Acorn_category] -= 1\n",
    "\n",
    "test_ids = set(test_ids)\n",
    "test_mask = [house_id in test_ids for house_id in energy_clean['LCLid']]\n",
    "train_mask = np.invert(test_mask)\n",
    "test_per_house_set = energy_clean[test_mask]\n",
    "train_per_house_set = energy_clean[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e0c77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_per_house_set.to_csv(f_data_path + f_energy_clean_name+\"_per_house.csv\", mode='w', index=False, header=True) \n",
    "test_per_house_set.to_csv(f_test_path + f_energy_clean_name+\"_per_house.csv\", mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90bf981",
   "metadata": {},
   "source": [
    "# Save Half hour Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb3608",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ffa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_info_hh = energy_hhour.merge(weather_h,left_on='tstp',right_on='date',how='left')\n",
    "# energy_info_hh.drop(['tstp'],axis=1,inplace=True)\n",
    "print(\"added weather\")\n",
    "energy_info_hh['holiday_ind'] = np.where(energy_info_hh['date'].dt.date.isin( holiday['Bank holidays']),1,0)\n",
    "print(\"added holiday\")\n",
    "energy_info_hh = energy_info_hh.merge(house_info, on = ['LCLid'],how='left')\n",
    "print(\"added acorn cat\")\n",
    "# energy_info_hh = energy_info_hh[['LCLid', 'date','energy(kWh/hh)', 'temperature', 'holiday_ind', 'Acorn_category_x']]\n",
    "# energy_info_hh.rename(columns={'energy(kWh/hh)':'energy','Acorn_category_x': 'Acorn_category'},inplace=True)\n",
    "energy_info_hh = energy_info_hh[['LCLid', 'date','energy(kWh/hh)', 'temperature', 'holiday_ind', 'Acorn_category']]\n",
    "energy_info_hh.rename(columns={'energy(kWh/hh)':'energy'},inplace=True)\n",
    "energy_hhour = None # Drop database for RAM sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "974663b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31079.0 30149.383399209488\n",
      "               date        energy   temperature   holiday_ind  Acorn_category\n",
      "count   5566.000000   5566.000000   5566.000000   5566.000000     5566.000000\n",
      "mean   30144.717391  30149.383399  30144.717391  30150.381064    30150.381064\n",
      "std     5369.865408   5370.625648   5369.865408   5370.629816     5370.629816\n",
      "min        0.000000      0.000000      0.000000      1.000000        1.000000\n",
      "25%    28674.000000  28679.000000  28674.000000  28680.000000    28680.000000\n",
      "50%    31079.000000  31084.000000  31079.000000  31085.000000    31085.000000\n",
      "75%    32707.000000  32712.000000  32707.000000  32713.000000    32713.000000\n",
      "max    39719.000000  39724.000000  39719.000000  39725.000000    39725.000000\n"
     ]
    }
   ],
   "source": [
    "households = energy_info_hh.groupby('LCLid').count()\n",
    "print(households['date'].median(), households['energy'].mean())\n",
    "print(households.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d157c6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "h_names_small_data_size = households[households['energy'] < 20000].index\n",
    "s = set(h_names_small_data_size)\n",
    "b = ~energy_info_hh['LCLid'].isin(s)\n",
    "energy_hh_clean = energy_info_hh[b]\n",
    "del b\n",
    "energy_hh_clean.reset_index(inplace=True,drop=True)\n",
    "del energy_info_hh # For RAM sake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7b2585be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jurek\\.pyenv\\pyenv-win\\versions\\3.7.4-amd64\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\Users\\jurek\\.pyenv\\pyenv-win\\versions\\3.7.4-amd64\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "energy_hh_clean['dayPrecent'] = -np.sin(energy_hh_clean['date'].dt.hour )/24 + (energy_hh_clean['date'].dt.minute )/(24*60)\n",
    "energy_hh_clean['yearPrecent'] = np.cos(energy_hh_clean['date'].dt.month - 1)/12 + (energy_hh_clean['date'].dt.day - 1)/(12*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "26c3e4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164349109 entries, 0 to 164349108\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   LCLid           object        \n",
      " 1   date            datetime64[ns]\n",
      " 2   energy          float32       \n",
      " 3   temperature     float32       \n",
      " 4   holiday_ind     bool          \n",
      " 5   Acorn_category  uint8         \n",
      " 6   dayPrecent      float16       \n",
      " 7   yearPrecent     float16       \n",
      "dtypes: bool(1), datetime64[ns](1), float16(2), float32(2), object(1), uint8(1)\n",
      "memory usage: 4.6+ GB\n"
     ]
    }
   ],
   "source": [
    "energy_hh_clean = energy_hh_clean.astype({'holiday_ind':'bool','Acorn_category':'uint8','dayPrecent':'f2','yearPrecent':'f2','temperature': 'f4','energy':'f4'})\n",
    "energy_hh_clean['id'] = [int(id[5:]) for id in energy_hh_clean['LCLid']]\n",
    "energy_hh_clean = energy_hh_clean.astype({'id':'uint16'})\n",
    "energy_hh_clean.drop(['LCLid'],axis=1,inplace=True)\n",
    "energy_hh_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "16868c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean = energy_hh_clean.sort_values(by=['id','date'])\n",
    "energy_hh_clean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f256d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean.drop(['date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1e18afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean.reset_index(drop=True,inplace=True)\n",
    "days_back = 4\n",
    "ind = np.arange(days_back)\n",
    "id = energy_hh_clean['id']\n",
    "for i in range(1,len(id)):\n",
    "    if id[i] != id[i - 1]: ind = np.append(ind, np.arange(i,i+days_back))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8cbefdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = energy_hh_clean.groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d628fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\n"
     ]
    }
   ],
   "source": [
    "ind = np.array([])\n",
    "\n",
    "for ii,i in enumerate(ids):\n",
    "    s = g.get_group(i).index[0]\n",
    "    ind = np.append(ind, np.arange(s,s+4))\n",
    "    progres_bar(ii+1, len(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "217dc35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(ind)\n",
    "# df.to_csv(f_data_path + \"ind.csv\", mode='w', index=False, header=True) \n",
    "ind = pd.read_csv(f_data_path + \"ind.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a5ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_hh_clean.to_feather(f_data_path + \"energy_hh_clean.feather\")\n",
    "energy_hh_clean = pd.read_feather(f_data_path + \"energy_hh_clean.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46fb6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearPercent fix\n",
    "energy_hh_clean['yearPrecent'] = (((energy_hh_clean['yearPrecent'] - 1/12) * 12/11) - 1/(12*30) ) * (12*30)/((12*30) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0de540b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_back = 4;data_tag='energy'\n",
    "index = 3\n",
    "#for index in range(0, days_back):\n",
    "energy_hh_clean[f'{data_tag}_{index}'] = 0.0 \n",
    "energy_hh_clean.loc[days_back:len(energy_hh_clean),f'{data_tag}_{index}'] =  energy_hh_clean[days_back-index -1:len(energy_hh_clean)-index -1][data_tag].values\n",
    "energy_hh_clean = energy_hh_clean.astype({f'{data_tag}_{index}':'f2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0cbc937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean.to_feather(f_data_path + \"temp.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eae63182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d12c3419",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c30d050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index                    128\n",
      "energy             657271712\n",
      "temperature        657271712\n",
      "holiday_ind        164317928\n",
      "Acorn_category     164317928\n",
      "dayPrecent         328635856\n",
      "yearPrecent        328635856\n",
      "pastET            1314543424\n",
      "energy_0           328635856\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164317928 entries, 0 to 164317927\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   energy          float32\n",
      " 1   temperature     float32\n",
      " 2   holiday_ind     bool   \n",
      " 3   Acorn_category  uint8  \n",
      " 4   dayPrecent      float16\n",
      " 5   yearPrecent     float16\n",
      " 6   pastET          float64\n",
      " 7   energy_0        float16\n",
      "dtypes: bool(1), float16(3), float32(2), float64(1), uint8(1)\n",
      "memory usage: 3.7 GB\n"
     ]
    }
   ],
   "source": [
    "print(energy_hh_clean.memory_usage())\n",
    "energy_hh_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4bfcff29",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17640/454459125.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jurek\\.pyenv\\pyenv-win\\versions\\3.7.4-amd64\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "ind = ind.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "297097d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = ind.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28a4c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean.drop(index=ind, inplace=True)\n",
    "energy_hh_clean.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961289d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#energy_hh_clean.to_feather(f_data_path + \"energy_hh_clean_all_pastET_fix_perc_id.feather\")\n",
    "energy_hh_clean = pd.read_feather(f_data_path + \"energy_hh_clean_all_pastET_fix_perc_id.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9aafe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af38928",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean['dayPrecent'] = -np.sin(energy_hh_clean['dayPrecent'])\n",
    "energy_hh_clean['yearPrecent'] = np.cos(energy_hh_clean['yearPrecent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793360ff",
   "metadata": {},
   "source": [
    "#### Add past day energy from the same time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107fbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean.drop(['energy_0','energy_1'],axis = 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c1f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = energy_hh_clean['id'].unique()\n",
    "g = energy_hh_clean.groupby('id')\n",
    "_ = g.get_group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7545f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\n"
     ]
    }
   ],
   "source": [
    "pastET = np.empty(len(energy_hh_clean),dtype='f2')\n",
    "ball = np.empty(len(energy_hh_clean))\n",
    "ind = 0\n",
    "for i, id in enumerate(ids):\n",
    "    # home = energy_hh_clean[energy_hh_clean['id'] == id].copy()\n",
    "    home = g.get_group(id).copy()\n",
    "    p = home['date'] - pd.to_timedelta(1, unit='d')\n",
    "    b = p.isin(home['date'])\n",
    "    ball[ind:ind+len(b)] = b\n",
    "    home['pastET'] = 0.0\n",
    "    home.loc[b,'pastET'] =  home.loc[home['date'].isin(p),'energy'].values.copy()\n",
    "    pastET[ind:ind+len(home)] = home['pastET'].values.copy()\n",
    "    ind += len(home)\n",
    "    progres_bar(i + 1,len(ids))\n",
    "\n",
    "energy_hh_clean['pastET'] = pastET\n",
    "del p,b,home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7402d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ball.astype('?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e27e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pastET,ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79f7ffba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    163738062\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8dde5e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\n"
     ]
    }
   ],
   "source": [
    "l = 2162078\n",
    "lenData = len(energy_hh_clean)\n",
    "progres_bar(0,lenData)\n",
    "x = [] \n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    a = energy_hh_clean[i:i+l]\n",
    "    x.append( a[df[i:i+l].values])\n",
    "    progres_bar(i+l,lenData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f5230d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_hh_clean = pd.concat(x, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "985ff0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>energy</th>\n",
       "      <th>temperature</th>\n",
       "      <th>holiday_ind</th>\n",
       "      <th>Acorn_category</th>\n",
       "      <th>dayPrecent</th>\n",
       "      <th>yearPrecent</th>\n",
       "      <th>id</th>\n",
       "      <th>pastET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-13 00:30:00</td>\n",
       "      <td>0.269</td>\n",
       "      <td>8.525</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020828</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-13 01:00:00</td>\n",
       "      <td>0.275</td>\n",
       "      <td>8.270</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041656</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-13 01:30:00</td>\n",
       "      <td>0.256</td>\n",
       "      <td>8.070</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-13 02:00:00</td>\n",
       "      <td>0.211</td>\n",
       "      <td>7.870</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083313</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-13 02:30:00</td>\n",
       "      <td>0.136</td>\n",
       "      <td>7.880</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104187</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163738057</th>\n",
       "      <td>2014-02-27 22:00:00</td>\n",
       "      <td>0.173</td>\n",
       "      <td>4.100</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0.916504</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>5567</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163738058</th>\n",
       "      <td>2014-02-27 22:30:00</td>\n",
       "      <td>0.205</td>\n",
       "      <td>4.015</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>5567</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163738059</th>\n",
       "      <td>2014-02-27 23:00:00</td>\n",
       "      <td>0.221</td>\n",
       "      <td>3.930</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0.958496</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>5567</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163738060</th>\n",
       "      <td>2014-02-27 23:30:00</td>\n",
       "      <td>0.222</td>\n",
       "      <td>7.465</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0.979004</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>5567</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163738061</th>\n",
       "      <td>2014-02-28 00:00:00</td>\n",
       "      <td>0.183</td>\n",
       "      <td>3.810</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>5567</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163738062 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date  energy  temperature  holiday_ind  \\\n",
       "0         2012-10-13 00:30:00   0.269        8.525        False   \n",
       "1         2012-10-13 01:00:00   0.275        8.270        False   \n",
       "2         2012-10-13 01:30:00   0.256        8.070        False   \n",
       "3         2012-10-13 02:00:00   0.211        7.870        False   \n",
       "4         2012-10-13 02:30:00   0.136        7.880        False   \n",
       "...                       ...     ...          ...          ...   \n",
       "163738057 2014-02-27 22:00:00   0.173        4.100        False   \n",
       "163738058 2014-02-27 22:30:00   0.205        4.015        False   \n",
       "163738059 2014-02-27 23:00:00   0.221        3.930        False   \n",
       "163738060 2014-02-27 23:30:00   0.222        7.465        False   \n",
       "163738061 2014-02-28 00:00:00   0.183        3.810        False   \n",
       "\n",
       "           Acorn_category  dayPrecent  yearPrecent    id  pastET  \n",
       "0                       1    0.020828     0.869629     2   0.000  \n",
       "1                       1    0.041656     0.869629     2   0.000  \n",
       "2                       1    0.062500     0.869629     2   0.000  \n",
       "3                       1    0.083313     0.869629     2   0.000  \n",
       "4                       1    0.104187     0.869629     2   0.000  \n",
       "...                   ...         ...          ...   ...     ...  \n",
       "163738057              17    0.916504     0.241699  5567   0.217  \n",
       "163738058              17    0.937500     0.241699  5567   0.209  \n",
       "163738059              17    0.958496     0.241699  5567   0.128  \n",
       "163738060              17    0.979004     0.241699  5567   0.051  \n",
       "163738061              17    0.000000     0.244385  5567   0.052  \n",
       "\n",
       "[163738062 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_hh_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a5907b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_hh_clean.to_feather(f_data_path + \"energy_hh_clean_pastET_dropped.feather\")\n",
    "#energy_hh_clean = pd.read_feather(f_data_path + \"energy_hh_clean_pastET.feather\")\n",
    "x = pd.read_feather(f_data_path + \"energy_hh_clean_pastET_dropped.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66709b",
   "metadata": {},
   "source": [
    "## Split batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9449d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#energy_hh_clean = pd.read_feather(f_data_path + \"energy_hh_clean_all.feather\")\n",
    "energy_hh_clean_data = energy_hh_clean.drop('energy', axis=1)\n",
    "energy_hh_clean_labels = energy_hh_clean['energy'].copy()\n",
    "del energy_hh_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631bc965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163716794"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(energy_hh_clean_data)\n",
    "#find best devisor for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e35a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(energy_hh_clean_data, energy_hh_clean_labels, train_size=0.9, random_state=123)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(energy_hh_clean_data, energy_hh_clean_labels, train_size=87/97, random_state=123)\n",
    "del energy_hh_clean_data\n",
    "del energy_hh_clean_labels\n",
    "# Data dims after train split ((147866994, 9), (16429666, 9), (147866994,), (16429666,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240aa05a",
   "metadata": {},
   "source": [
    "## STD Scale and save X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ccc1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit X Train\n",
      "fit X Test██████████████████████████████████████████████████████████████████████████████████████████| 99.89%\n",
      "|██████████████████████████████████████████████████████████████████████████████████████████████████-| 98.97%\r"
     ]
    }
   ],
   "source": [
    "s = StandardScaler()\n",
    "# 97, 194, 1067, 2134, 7699, 84689,169378,746803,1493606,8214833,16429666\n",
    "# train batches size = 99\n",
    "# test batches size = 11\n",
    "l = 1493606\n",
    "lenData = len(X_train)\n",
    "print(\"fit X Train\")\n",
    "progres_bar(0,lenData)\n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    s.partial_fit(X_train[i:i+l])\n",
    "    progres_bar(i+l,lenData)\n",
    "\n",
    "lenData = len(X_test)\n",
    "print(\"fit X Test\")\n",
    "progres_bar(0,lenData)\n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    s.partial_fit(X_test[i:i+l])\n",
    "    progres_bar(i+l,lenData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfe6e51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transfor X Train\n",
      "transfor X Test██████████████████████████████████████████████████████████████████████████████████████| 100.00%\n",
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\r"
     ]
    }
   ],
   "source": [
    "l = 1493606\n",
    "lenData = len(X_train)\n",
    "col = X_train.columns\n",
    "print(\"transfor X Train\")\n",
    "progres_bar(0,lenData)\n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    data_scaled = pd.DataFrame(s.transform(X_train[i:i+l]),columns=col)\n",
    "    data_scaled.to_feather(f_data_path + f\"HHData/xtrain{i//l}.feather\")\n",
    "    progres_bar(i+l,lenData)\n",
    "\n",
    "lenData = len(X_test)\n",
    "print(\"transfor X Test\")\n",
    "progres_bar(0,lenData)\n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    data_scaled = pd.DataFrame(s.transform(X_test[i:i+l]),columns=col)\n",
    "    data_scaled.to_feather(f_data_path + f\"HHData/xtest{i//l}.feather\")\n",
    "    progres_bar(i+l,lenData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d693a",
   "metadata": {},
   "source": [
    "## Batch data and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c58a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87.0, 10.0, 87.0, 10.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)/ 1687802, len(X_test) / 1687802, len(Y_train) / 1687802, len(Y_test)/ 1687802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c2e9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X Train\n",
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\n",
      "Batch Y train\n",
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\n"
     ]
    }
   ],
   "source": [
    "# l = 1493606\n",
    "l = 1687802\n",
    "path = f_data_path + \"HHDataAll/\"\n",
    "lenData = len(X_train)\n",
    "\n",
    "col = X_train.columns\n",
    "print(\"Batch X Train\")\n",
    "progres_bar(0,lenData)\n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    data = X_train[i:i+l].reset_index(drop=True)\n",
    "    data.to_feather(path + f\"xtrain{i//l}.feather\")\n",
    "    progres_bar(i+l,lenData)\n",
    "\n",
    "#lenData = len(Y_train)\n",
    "print(\"Batch Y train\")\n",
    "progres_bar(0,lenData)\n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    ydata = Y_train[i:i+l].to_frame().reset_index(drop=True)\n",
    "    ydata.to_feather(path + f\"ytrain{i//l}.feather\")\n",
    "    progres_bar(i+l,lenData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7212d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X Test\n",
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\n",
      "Batch Y Test\n",
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\n"
     ]
    }
   ],
   "source": [
    "l = 1687802\n",
    "path = f_data_path + \"HHDataAll/\"\n",
    "\n",
    "lenData = len(X_test)\n",
    "print(\"Batch X Test\")\n",
    "progres_bar(0,lenData)\n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    data = X_test[i:i+l].reset_index(drop=True)\n",
    "    data.to_feather(path + f\"xtest{i//l}.feather\")\n",
    "    progres_bar(i+l,lenData)\n",
    "\n",
    "lenData = len(Y_test)\n",
    "print(\"Batch Y Test\")\n",
    "progres_bar(0,lenData)\n",
    "for i in range(0,lenData,l): ## Looping through batches\n",
    "    ydata = Y_test[i:i+l].to_frame().reset_index(drop=True)\n",
    "    ydata.to_feather(path + f\"ytest{i//l}.feather\")\n",
    "    progres_bar(i+l,lenData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "bac3ff73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Acorn_category</th>\n",
       "      <th>dayPrecent</th>\n",
       "      <th>yearPrecent</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.643438e+08</td>\n",
       "      <td>1.643179e+08</td>\n",
       "      <td>1.643491e+08</td>\n",
       "      <td>1.643179e+08</td>\n",
       "      <td>1.643179e+08</td>\n",
       "      <td>1.643491e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.120399e-01</td>\n",
       "      <td>1.095281e+01</td>\n",
       "      <td>8.634995e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.759542e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.961209e-01</td>\n",
       "      <td>6.022693e+00</td>\n",
       "      <td>4.866891e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.665081e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.640000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.612061e-02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.800000e-02</td>\n",
       "      <td>6.625000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>3.444824e-01</td>\n",
       "      <td>1.288000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.170000e-01</td>\n",
       "      <td>1.049000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>6.279297e-01</td>\n",
       "      <td>2.712000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.400000e-01</td>\n",
       "      <td>1.521500e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>8.637695e-01</td>\n",
       "      <td>4.295000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.076100e+01</td>\n",
       "      <td>3.240000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>9.790039e-01</td>\n",
       "      <td>1.085938e+00</td>\n",
       "      <td>5.567000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             energy   temperature  Acorn_category    dayPrecent   yearPrecent  \\\n",
       "count  1.643438e+08  1.643179e+08    1.643491e+08  1.643179e+08  1.643179e+08   \n",
       "mean   2.120399e-01  1.095281e+01    8.634995e+00           NaN           NaN   \n",
       "std    2.961209e-01  6.022693e+00    4.866891e+00  0.000000e+00  0.000000e+00   \n",
       "min    0.000000e+00 -5.640000e+00    0.000000e+00  0.000000e+00  8.612061e-02   \n",
       "25%    5.800000e-02  6.625000e+00    5.000000e+00  2.500000e-01  3.444824e-01   \n",
       "50%    1.170000e-01  1.049000e+01    6.000000e+00  5.000000e-01  6.279297e-01   \n",
       "75%    2.400000e-01  1.521500e+01    1.200000e+01  7.500000e-01  8.637695e-01   \n",
       "max    1.076100e+01  3.240000e+01    1.800000e+01  9.790039e-01  1.085938e+00   \n",
       "\n",
       "                 id  \n",
       "count  1.643491e+08  \n",
       "mean   2.759542e+03  \n",
       "std    1.665081e+03  \n",
       "min    2.000000e+00  \n",
       "25%    1.288000e+03  \n",
       "50%    2.712000e+03  \n",
       "75%    4.295000e+03  \n",
       "max    5.567000e+03  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_hh_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d39fb97",
   "metadata": {},
   "source": [
    "## Split household data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5b2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddTagDaysBack(data,index = 0,data_tag='energy', days_back = 4 ):\n",
    "    data[f'{data_tag}_{index}'] = 0.0 \n",
    "    data.loc[days_back:len(data),f'{data_tag}_{index}'] =  data[days_back-index -1:len(data)-index -1][data_tag].values\n",
    "    data = data.astype({f'{data_tag}_{index}':'f2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2311c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#energy_hh_clean = pd.read_feather(f_data_path + \"energy_hh_clean.feather\")\n",
    "energy_hh_clean = pd.read_feather(f_data_path + \"energy_hh_clean_all_pastET_fix_perc_id.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e24bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateHouseSampleByID(id,data=energy_hh_clean,path=\"HHDataId/\"):\n",
    "    e= data['id'] == id\n",
    "    id2 = data.loc[e].reset_index(drop=True)\n",
    "    id2 = id2.drop(['id'],axis=1)\n",
    "    id2.to_feather(f_data_path+path+f\"{id}.feather\")\n",
    "    # for i in range(4):\n",
    "    #     AddTagDaysBack(id2,i,days_back=4)\n",
    "    # id2 = id2.drop(['date','id'],axis=1)\n",
    "    # id2.to_feather(f_data_path+f\"TestId{id}.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68714c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = energy_hh_clean['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31aee475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00%\n"
     ]
    }
   ],
   "source": [
    "for i,id in enumerate(ids):\n",
    "    CreateHouseSampleByID(id)\n",
    "    progres_bar(i+1,len(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee16e1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "CreateHouseSampleByID(2)\n",
    "CreateHouseSampleByID(3)\n",
    "CreateHouseSampleByID(69)\n",
    "CreateHouseSampleByID(420)\n",
    "CreateHouseSampleByID(100)\n",
    "CreateHouseSampleByID(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157b53e",
   "metadata": {},
   "source": [
    "# Save daily AVG data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dd082c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housecount = energy.groupby('date')[['LCLid']].nunique()\n",
    "energy_avg = energy.groupby('date')[['energy_sum']].sum()\n",
    "energy_avg = energy_avg.merge(housecount, on = ['date'])\n",
    "energy_avg = energy_avg.reset_index()\n",
    "energy_avg['avg_energy'] =  energy_avg['energy_sum']/energy_avg['LCLid']\n",
    "\n",
    "energy_avg['day'] = [d.day for d in energy_avg['date']]\n",
    "energy_avg['month'] = [d.month for d in energy_avg['date']]\n",
    "energy_avg['year'] = [d.year for d in energy_avg['date']]\n",
    "\n",
    "weather_energy_avg =  energy_avg.merge(weather,on='date')\n",
    "weather_energy_avg = weather_energy_avg.merge(holiday, left_on = 'date',right_on = 'Bank holidays',how = 'left')\n",
    "weather_energy_avg['holiday_ind'] = np.where(weather_energy_avg['Bank holidays'].isna(),0,1)\n",
    "weather_energy_avg = weather_energy_avg[['avg_energy', 'day', 'month', 'temperatureMax', 'holiday_ind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0988fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_energy_avg.to_csv(\"energy_avg_all.csv\", mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d90b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_energy_avg.to_csv(f_energy_avg_name+f_holiday_data_sufix+\".csv\", mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b74b793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_avg_train_set, we_avg_test_set = train_test_split(weather_energy_avg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7db1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_avg_train_set.to_csv(f_energy_avg_name+\"_train.csv\", mode='w', index=False, header=True) \n",
    "we_avg_test_set.to_csv(f_energy_avg_name+\"_test.csv\", mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05370fd8",
   "metadata": {},
   "source": [
    "# Save HHourly AVG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92d4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "housecount = energy_hh_clean.groupby('date')[['LCLid']].nunique()\n",
    "energy_avg = energy_hhour.groupby('date')[['energy(kWh/hh)']].sum()\n",
    "energy_avg = energy_avg.merge(housecount, on = ['date'])\n",
    "energy_avg = energy_avg.reset_index()\n",
    "energy_avg['avg_energy'] =  energy_avg['energy(kWh/hh)']/energy_avg['LCLid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72018c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f5c464f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'to_Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24400/1951659445.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menergy_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menergy_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'temperature'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_Series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jurek\\.pyenv\\pyenv-win\\versions\\3.7.4-amd64\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         raise AttributeError(\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[1;34mf\"'{type(self).__name__}' object has no attribute '{attr}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         )\n\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'to_Series'"
     ]
    }
   ],
   "source": [
    "energy_avg = energy_avg.merge(g[['temperature']].to_Series(), on=['date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34d5d3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-23 09:00:00</td>\n",
       "      <td>0.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-11-23 09:30:00</td>\n",
       "      <td>0.280500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-11-23 10:00:00</td>\n",
       "      <td>0.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-11-23 10:30:00</td>\n",
       "      <td>0.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-11-23 11:00:00</td>\n",
       "      <td>0.110286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39717</th>\n",
       "      <td>2014-02-27 22:00:00</td>\n",
       "      <td>0.300075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39718</th>\n",
       "      <td>2014-02-27 22:30:00</td>\n",
       "      <td>0.285482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39719</th>\n",
       "      <td>2014-02-27 23:00:00</td>\n",
       "      <td>0.252565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39720</th>\n",
       "      <td>2014-02-27 23:30:00</td>\n",
       "      <td>0.215409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39721</th>\n",
       "      <td>2014-02-28 00:00:00</td>\n",
       "      <td>0.209237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39722 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date    energy\n",
       "0     2011-11-23 09:00:00  0.284500\n",
       "1     2011-11-23 09:30:00  0.280500\n",
       "2     2011-11-23 10:00:00  0.153333\n",
       "3     2011-11-23 10:30:00  0.098000\n",
       "4     2011-11-23 11:00:00  0.110286\n",
       "...                   ...       ...\n",
       "39717 2014-02-27 22:00:00  0.300075\n",
       "39718 2014-02-27 22:30:00  0.285482\n",
       "39719 2014-02-27 23:00:00  0.252565\n",
       "39720 2014-02-27 23:30:00  0.215409\n",
       "39721 2014-02-28 00:00:00  0.209237\n",
       "\n",
       "[39722 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af28aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_avg = energy_hhour.groupby('tstp')[['energy(kWh/hh)']].mean().reset_index()\n",
    "\n",
    "# housecount = energy_hhour.groupby('tstp')[['LCLid']].nunique()\n",
    "# energy_avg = energy_hhour.groupby('tstp')[['energy(kWh/hh)']].sum()\n",
    "# energy_avg = energy_avg.merge(housecount, on = ['tstp'])\n",
    "# energy_avg = energy_avg.reset_index()\n",
    "# energy_avg['avg_energy'] =  energy_avg['energy(kWh/hh)']/energy_avg['LCLid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "27eda009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-11-01 00:00:00 2014-03-31 22:30:00\n",
      "2011-11-23 09:00:00 2014-02-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(min(weather_h['date']),max(weather_h['date']))\n",
    "print(min(energy_avg_plus['tstp']),max(energy_avg_plus['tstp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ae62adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_avg['minute'] = [d.minute for d in energy_avg['tstp']]\n",
    "energy_avg['hour'] = [d.hour for d in energy_avg['tstp']]\n",
    "energy_avg['day'] = [d.day for d in energy_avg['tstp']]\n",
    "energy_avg['month'] = [d.month for d in energy_avg['tstp']]\n",
    "energy_avg['year'] = [d.year for d in energy_avg['tstp']]\n",
    "\n",
    "energy_avg_plus = energy_avg.merge(weather_h, left_on = 'tstp',right_on = 'date', how = 'left')\n",
    "energy_avg_plus = energy_avg_plus.dropna(subset=['temperature'])\n",
    "\n",
    "energy_avg_plus['date'] = energy_avg_plus['date'].dt.date\n",
    "energy_avg_plus = energy_avg_plus.merge(holiday, left_on = 'date',right_on = 'Bank holidays',how = 'left')\n",
    "energy_avg_plus['holiday_ind'] = np.where(energy_avg_plus['Bank holidays'].isna(),0,1)\n",
    "\n",
    "energy_avg_plus = energy_avg_plus[['avg_energy', 'minute', 'hour','day', 'month', 'year', 'temperature', 'holiday_ind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7d463e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_avg_plus.to_csv(f_data_path + f_energy_avg_hhourly_name+\"_all.csv\", mode='w', index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "558e7ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38858\n",
       "1      864\n",
       "Name: holiday_ind, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_avg_plus['holiday_ind'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "185335a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipeline_avg = Pipeline([\n",
    "       # ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('avg_tr', AverageTransformer()),\n",
    "        ('discreat_date_tr', DiscreatDate()),\n",
    "        ('weather_tr', WeatherDataMerge(weather=weather)),\n",
    "        ('holiday_tr', HolidayDataMerge(holiday=holiday)),\n",
    "        ('select_tr', Select(features=['avg_energy', 'day', 'month', 'temperatureMax', 'holiday_ind'])),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "energy_tr = pipeline_avg.fit_transform(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9a3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "59acfeb3f47181c7d27a6d5fd292581940b5ce2ca017d2014e8174671486b380"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
