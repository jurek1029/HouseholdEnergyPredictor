{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 28, 20)            3920      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 560)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                5610      \n",
      "=================================================================\n",
      "Total params: 9,530\n",
      "Trainable params: 9,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28), name='input'),\n",
    "    tf.keras.layers.LSTM(20, time_major=False, return_sequences=True),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 7s 1us/step\n",
      "11501568/11490434 [==============================] - 7s 1us/step\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 41s 10ms/step - loss: 0.3423 - accuracy: 0.8979\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1254 - accuracy: 0.9620\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0906 - accuracy: 0.9722\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0724 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0611 - accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05477413162589073, 0.9807999730110168]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# Change this to True if you want to test the flow rapidly.\n",
    "# Train with a small dataset and only 1 epoch. The model will work poorly\n",
    "# but this provides a fast way to test if the conversion works end to end.\n",
    "_FAST_TRAINING = False\n",
    "_EPOCHS = 5\n",
    "if _FAST_TRAINING:\n",
    "  _EPOCHS = 1\n",
    "  _TRAINING_DATA_COUNT = 1000\n",
    "  x_train = x_train[:_TRAINING_DATA_COUNT]\n",
    "  y_train = y_train[:_TRAINING_DATA_COUNT]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=_EPOCHS)\n",
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_lstm\\assets\n"
     ]
    }
   ],
   "source": [
    "run_model = tf.function(lambda x: model(x))\n",
    "# This is important, let's fix the input size.\n",
    "BATCH_SIZE = 1\n",
    "STEPS = 28\n",
    "INPUT_SIZE = 28\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = \"keras_lstm\"\n",
    "model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    data = np.random.random((1,28,28))\n",
    "    yield [data.astype(np.float32)]\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "# #                                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "# # converter.experimental_new_converter = True\n",
    "# # Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "# open(f_modele_lite_path + prefix +'quantized.tflite', \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59acfeb3f47181c7d27a6d5fd292581940b5ce2ca017d2014e8174671486b380"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
